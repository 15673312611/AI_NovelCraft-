# AI配置使用说明

## 🎉 改造完成！

所有核心AI功能现在都支持在前端配置不同的AI服务商了！

## 📝 快速开始

### 1. 配置AI服务（首次使用必做）

1. 访问**设置页面**（Settings）
2. 选择你想使用的AI服务商：
   - **DeepSeek** - 高性价比，适合长文本
   - **通义千问** - 阿里云服务，多种规格
   - **Kimi (月之暗面)** - 超长上下文（最高262K）
3. 输入你的**API Key**
4. 选择**模型**
5. 点击**保存配置**

### 2. 开始使用

配置保存后，以下功能会自动使用你配置的AI服务：

#### ✅ 卷大纲生成
- 点击"按原主题生成所有卷大纲" - 现已完全支持！
- 单个卷大纲生成也支持

#### ✅ AI写作
- 章节写作（流式输出）
- 实时看到AI生成的内容

#### ✅ AI消痕
- 流式AI消痕
- 非流式AI消痕

#### ✅ 形容词挖掘
- 批量挖掘可疑形容词

## 🔧 支持的AI服务商

### DeepSeek
```
服务商: DeepSeek
默认URL: https://api.deepseek.com
推荐模型:
  - deepseek-chat (通用对话)
  - deepseek-coder (代码生成)
  - deepseek-v3-1-250821-thinking (思考模型)
```

### 通义千问
```
服务商: 通义千问
默认URL: https://dashscope.aliyuncs.com/compatible-mode/v1
推荐模型:
  - qwen-turbo (快速)
  - qwen-plus (平衡)
  - qwen-max (高质量)
  - qwen-max-longcontext (长上下文)
```

### Kimi (月之暗面)
```
服务商: Kimi
默认URL: https://api.moonshot.cn
推荐模型:
  - kimi-k2-turbo-preview (推荐，262K上下文)
  - kimi-k2-0905-preview (262K)
  - kimi-latest-128k (131K)
  - kimi-thinking-preview (深度推理)
  - moonshot-v1-128k (兼容)
```

## ⚠️ 注意事项

### 配置存储
- 所有AI配置仅保存在**浏览器本地缓存**中
- 不会上传到服务器
- 清除浏览器缓存会删除配置
- 不同浏览器需要分别配置

### API密钥安全
- 请妥善保管你的API密钥
- 建议使用有额度限制的密钥
- API密钥通过HTTPS传输，相对安全

### 首次使用
- 必须先在设置页面配置AI服务
- 如果未配置，调用AI功能时会提示"请先在设置页面配置AI服务"

## 🐛 常见问题

### Q: 点击生成大纲没有反应？
**A**: 检查以下几点：
1. 是否在设置页面配置了AI服务？
2. API Key是否正确？
3. 查看浏览器控制台是否有错误信息
4. 查看后端日志是否有报错

### Q: 提示"AI配置无效"？
**A**: 
1. 检查API Key是否填写
2. 检查是否选择了模型
3. 检查是否选择了服务商
4. 尝试重新配置并保存

### Q: 换了浏览器配置丢失？
**A**: 
配置保存在浏览器本地，换浏览器需要重新配置。

### Q: 想更换AI服务商？
**A**: 
直接在设置页面重新选择服务商、输入新的API Key并保存即可。

## 📊 功能状态

| 功能 | 状态 | 说明 |
|------|------|------|
| 章节写作 | ✅ 完全支持 | 流式输出 |
| AI消痕 | ✅ 完全支持 | 流式和非流式 |
| 批量生成卷大纲 | ✅ 完全支持 | 新修复！ |
| 单个卷大纲生成 | ✅ 完全支持 | 异步生成 |
| 形容词挖掘 | ✅ 完全支持 | 批量并发 |

## 💡 最佳实践

### 选择模型建议

**日常写作推荐：**
- DeepSeek: `deepseek-chat`
- 通义千问: `qwen-plus`
- Kimi: `kimi-latest`

**长文本/超长上下文：**
- DeepSeek: `deepseek-v3-1-250821-thinking`
- 通义千问: `qwen-max-longcontext`
- Kimi: `kimi-k2-turbo-preview` (262K!)

**复杂推理任务：**
- Kimi: `kimi-thinking-preview`

### 成本控制
1. 选择合适的模型（不一定要最贵的）
2. Kimi的128K模型已经足够处理大部分场景
3. 批量生成大纲时注意卷的数量

## 🎯 测试建议

### 立即可以测试
1. ✅ 在设置页面配置AI（使用DeepSeek或通义千问）
2. ✅ 创建一个小说，添加几个卷
3. ✅ 点击"按原主题生成所有卷大纲"
4. ✅ 观察是否正常生成

### 预期结果
- 不再提示缺少API配置
- 能够正常调用你配置的AI服务
- 生成的大纲符合你选择的AI模型风格

## 📚 相关文档

- `AI配置改造说明.md` - 详细的技术改造说明
- `AI配置改造进度.md` - 改造进度和状态

## 🚀 下一步

现在所有核心功能都已支持前端AI配置，你可以：

1. 立即测试"按原主题生成所有卷大纲"功能
2. 尝试不同的AI服务商，比较效果
3. 根据需求选择最合适的模型
4. 享受灵活的AI配置带来的便利！

---

**祝你创作顺利！** 🎉
